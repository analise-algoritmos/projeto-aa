\chapter{Conclusões}
A análise experimental apresentada ao longo deste trabalho permitiu compreender de maneira aprofundada o comportamento prático dos diferentes algoritmos de ordenação quando submetidos a um conjunto padronizado de instâncias. Embora a teoria da complexidade ofereça uma previsão geral sobre o desempenho esperado, os experimentos revelam nuances importantes que somente a avaliação empírica é capaz de demonstrar.

Inicialmente, observou-se que os algoritmos lineares que não dependem do intervalo dos valores — como FlashSort, SpreadSort e Burstsort — apresentam desempenho excepcionalmente eficiente, mantendo tempos de execução muito baixos mesmo para entradas de cem mil elementos. Esse comportamento confirma não apenas a linearidade teórica, mas também evidencia a eficácia prática dessas implementações. Por outro lado, algoritmos lineares cuja complexidade envolve o parâmetro adicional \(M\), como Counting Sort e Pigeonhole Sort, mostraram-se impraticáveis diante de um intervalo extremamente amplo de valores. Este fenômeno ressalta a importância de analisar não apenas a ordem assintótica, mas também as condições reais de uso, especialmente quando o desempenho depende de características específicas dos dados.

Nos algoritmos classificados como \(O(N \log N)\), verificou-se que a diferença entre implementações pode ser significativa. Timsort, por exemplo, destacou-se pela estabilidade e excelente desempenho, muito em função de sua estratégia híbrida e da capacidade de explorar trechos já ordenados. Em contraste, algoritmos como In-place MergeSort e Tournament Sort apresentaram overhead elevado, evidenciando que uma boa complexidade teórica não garante necessariamente bom desempenho prático quando os custos internos da implementação são altos. Assim, fica claro que, dentro da mesma classe assintótica, a escolha do algoritmo mais adequado depende diretamente do contexto e das características específicas da aplicação.

Os algoritmos quadráticos, como previsto, demonstraram limitações severas conforme o tamanho das entradas aumentava. Bubble Sort e Gnome Sort tornaram-se inviáveis para instâncias maiores, com tempos de execução crescendo de forma abrupta. No entanto, algoritmos como Shell Sort e Comb Sort apresentaram desempenho consideravelmente melhor, mostrando que estratégias de melhoria podem reduzir drasticamente o impacto prático da complexidade quadrática pura. Mesmo assim, sua utilização em cenários de grande escala deve ser evitada quando alternativas mais eficientes estão disponíveis.

De modo geral, os resultados experimentais confirmam a hierarquia esperada entre as classes de complexidade, mas também demonstram que a prática envolve fatores adicionais, como otimizações internas, overhead computacional, consumo de memória e organização dos dados. Essa constatação reforça a importância de complementar a análise teórica com experimentos empíricos, garantindo que o algoritmo selecionado seja não apenas assintoticamente eficiente, mas também adequado às condições reais de uso.

Por fim, este estudo abre caminho para investigações futuras. Avaliações específicas do impacto de \(M\) nos algoritmos lineares baseados em contagem, análises detalhadas do consumo de memória ou ainda estudos comparativos em linguagens compiladas podem oferecer insights adicionais sobre o comportamento desses algoritmos em diferentes cenários. Ademais, é possível explorar as limitações ciadas no capítulo anterior, para complementação dos resultados já obtidos. A combinação entre análise teórica e experimental mostra-se, portanto, fundamental para a compreensão completa do desempenho de algoritmos de ordenação.